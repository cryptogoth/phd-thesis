\section{Quantum Compiling Background}
\label{sec:qcompile-bg}

Quantum compiling as a general task of approximating $SU(2^n)$ matrices
using 

The image to keep in mind throughout this entire section is shown in
Figure \ref{fig:qcompile}.

\begin{figure}
\begin{center}
\begin{displaymath}
\begin{array}{ccc}

%%%%%%%%%%%%%%%%
% Source circuit
%\underbrace{
\begin{array}{c}
S = 2 \\
\Qcircuit @C=0.5em @R=.5em { 
	& \multigate{4}{U_1} & \qw & \multigate{4}{U_2} & \qw \\ 
	& \ghost{U_1}        & \qw & \ghost{U_2}        & \qw \\
	& \ghost{U_1}        & \qw & \ghost{U_2}        & \qw \\
	& \ghost{U_1}        & \qw & \ghost{U_2}        & \qw \\
	& \ghost{U_1}        & \qw & \ghost{U_2}        & \qw 
	\gategroup{1}{2}{5}{4}{.7em}{--}
}\\
\xymatrix {
  & D=2 \ar[l] \ar[r] & \\
 }
\end{array}
%}_{C}

%& 
%\begin{array}{c}
%\textsc{Quantum Compiler} \\
\rightarrow
%\end{array}
%&

%%%%%%%%%%%%%%%%
% Target circuit
%\underbrace{
\begin{array}{c}
S' = 15 \\
\Qcircuit @C=0.5em @R=.5em { 
	& \gate{H} & \qw & \ctrl{1} & \gate{H} & \qw & \qw      & \ctrl{1} & \qw \\ 
	& \gate{H} & \qw & \targfix & \ctrl{2} & \qw & \gate{K} & \targfix & \qw \\
	& \gate{H} & \qw & \gate{K} & \qw      & \qw & \gate{H} & \qw      & \qw \\
	& \gate{H} & \qw & \ctrl{1} & \targfix & \qw & \gate{H} & \qw      & \qw \\
	& \gate{H} & \qw & \targfix & \gate{H} & \qw & \qw      & \qw      & \qw
	\gategroup{1}{2}{5}{9}{.7em}{--}
}\\
\xymatrix {
  & & D'=5 \ar[ll] \ar[rr] & & \\
 }
\end{array}
%}_{C}

\end{array}
\end{displaymath}

\caption{Quantum circuit synthesis into single-qubit gates and $CNOT$.}
\label{fig:qcompile}
\end{center}
\end{figure}

can be subdivided into more special-purpose tasks along several axes,
which are cross-cutting themes in any literature review of quantum compilers.
These themes also provide a context for understanding the resource consumption
for a wide variety of quantum compilers. We provide such a resource
comparison in Section \ref{sec:qcompile-compare}.

These axes are:

\begin{enumerate}
\item single-qubit compiling versus multi-qubit compiling
\item exact synthesis versus approximative quantum compiling
\item deterministic versus probabilistic quantum compiling
\item compilers with provable upper bounds versus conjectured upper bounds
\end{enumerate}

The first axis is 
single-qubit compiling
(mentioned previously in Section \ref{subsec:qcompile-single}) versus
multi-qubit compiling. Some algorithms which work on single-qubit compiling
can be generalized directly to the multi-qubit case. In fact, all known
examples of these generalized algorithms can accept an arbitrary circuit
basis $\mathcal{B}$ \cite{Amy2012,Dawson2005,Fowler2011,Booth2012}.
That is, they do not exploit any special structure of
a particular basis. The circuit basis is another input to the algorithm,
possibly to an additional classical preprocessing step. Whether the algorithm
is a single-qubit or a multi-qubit algorithm depends on whether the basis
is single-qubit or multi-qubit.

There is an intermediate point on this axis, between single-qubit and multi-qubit,
which is the reduction of a multi-qubit circuit into a basis of
single-qubit and two-qubit gates. This task is often called \emph{quantum circuit synthesis},
and we will discuss it in Section \ref{subsec:qcompile-multi}.

The second axis is compiling a circuit exactly or approximately.
Exact synthesis refers to the case of determining whether a
target circuit $C$ is implementable from a basis $\mathcal{B}$
with no error ($\epsilon = 0$). If this is possible, a quantum compiler
should return the sequence of gates which constitute the exact
synthesis. Furthermore, exact synthesizers often have a goal of
returning the \emph{optimal} sequence of compiled gates, that is,
one with minimal length $\ell$. In the compilers that we review
in Section \ref{sec:qcompile-review}, $\ell$ stands for the optimal
depth of non-Clifford resources in a basis which also contains Clifford
gates. Therefore, counting $\ell$ as non-Clifford resources is always
within a constant factor of counting $\ell$ as all resources, and so we
will not distinguish between the two,.

Exact synthesizers often enumerate over all circuits of
a certain length from a certain basis $\mathcal{B}$. Therefore, their
resources are upper bounded by a brute force search, which takes
time upper-bounded by $|\mathcal{B}|^{\ell}$.
Approximative quantum compiling conforms to our usual notion where
$\epsilon > 0$, and achieving smaller error costs more resources. Many
exact synthesis algorithms can be used to build basic approximations
for the Solovay-Kitaev algorithm more efficiently, and therefore help
achieve better approximative upper bounds as verified by numerical
simulation over random unitaries.

What is the relationship between $\ell$ and $\epsilon$? By a volume
argument, the minimum number of points in an $\epsilon_0$-net for
$SU(d=2^n)$ is $1/(\epsilon^{d^2 - 1})$. If we were to do an approximative
search within error $\epsilon_0$
for a circuit in $SU(d)$ which is known to have optimal length
$\ell$, we would have to enumerate all sequences from a basis $\mathcal{B}$
of up to length $\ell$ in the worst case, of which there are $|\mathcal{B}|^{\ell}$.
Therefore, we have the following relationship.

\begin{equation}
\ell \ge (d^2 - 1) \log_{|B|}(1/\epsilon) + O(1)
\end{equation}

The third axis is whether a quantum compiling algorithm uses randomness
or is completely deterministic. For known randomized algorithms, it is
an open problem whether the algorithm can be derandomized or not
\cite{Kliuchnikov2012a}, and numerical verification is necessary to
show the desired distribution of running times.

The fourth axis is whether a quantum compiler has upper bounds
(usually on running time or compiled sequence length) that are provable or
based on a conjecture. Both deterministic and randomized
algorithms can have provable upper bounds, although
in the latter case, one calculates the average-case and upper bounds the
variance. Likewise, both deterministic and randomized algorithms can
be based on a conjecture.

These four axes can be used to classify quantum compilers, although some
algorithms can be placed in multiple categories. For example, many
single-qubit quantum compilers which perform exact synthesis can be
incorporated into a hybrid algorithm which then performs
approximation. And of course, some single-qubit quantum compilers can be generalized
into multi-qubit algorithms.

A fifth axis could be formed, which is whether the compiled circuit requires
arbitrarily long interactions for $CNOT$ or is nearest-neighbor. Such a
quantum compiler could also divide up a compiled circuit into an optimal
number of modules on \textsf{2D CCNTCM} to also minimize module depth and
module size (inter-module teleportations). This is an interesting direction
for future research.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Quantum Compiler Resources}

Just as a quantum algorithm with arbitrary long-range interactions incurs
some overhead in being mapped to a nearest-neighbor architecture,
a quantum compiler itself is an algorithm. It always has a classical
component, which runs on a digital computer, and transforms a classical
description of an input quantum circuit into an output circuit from
a basis $\mathcal{B}$. The compiled output circuit then runs on a
quantum computer. In general, the compiled output circuit $\tilde{C}$ consumes
resources which are greater than those of the input circuit $C$.

\begin{description}
\item[classical runtime $R$:] the classical time it takes to return a 
compiled quantum circuit.
\item[input depth $D$:] the depth of the input quantum circuit in arbitrary
$n$-qubit gates.
\item[input size $S$:] the size of the input quantum circuit in arbitrary
$n$-qubit gates.
\item[input width $W$:] the width of the input quantum circuit in qubits.
\item[compiled depth $D'$:] the compiled quantum circuit depth, equal to
the compiled sequence length for single-qubit circuits.
\item[compiled size $S$:] the compiled quantum circuit size, which is
identical to compiled depth if no ancillae are used (compiled width is zero).
\item[compiled width $W$:] the compiled quantum circuit width, which includes
the width of the input circuit as well as any ancillae introduced by
the compiler.
\end{description}

All but the first resource are quantum in nature, and follow the definitions
for circuit resources from Chapter \ref{chap:factor-polylog}. Because
compilation incurs some overhead, we have $D' \ge D$, $S' \ge S$, and
$W' \ge W$.

It's also known that
in order to approximate a circuit with $S$ gates to a total precision of
$\epsilon$
requires each gate to be approximated to a precision of
$n = O(\log(S/\epsilon)$ \cite{Lloyd1995}. We denote this per-gate precision
$n$, since it serves as an independent parameter for compiling. For
single-qubit gates, $S = 1$, and this corresponds exactly with our previous
definition for $n$ in Section \ref{sec:qcompile-basis}.

We do not measure classical space requirements, although these may be
exponential. This would be a useful metric for comparison for future work.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Decomposition to Single-Qubit and $CNOT$}
\label{subsec:qcompile-multi}

Restricting ourselves to the simplest case of
single-qubit circuits allows us to exploit a lot of structure
in the group $U(2)$ (or its related subgroups $SU(2)$ and $PSU(2)$).
From a volume argument, we can derive a general
lower bound for the efficiency of the multi-qubit case \cite{Harrow2002},
as well as determine how our compiling efficiency scales with dimensionality.
Any
SK-style algorithm produces worst-case sequence lengths $\ell_d$ that
are longer than worst-case single-qubit sequence lengths $\ell_1$ by a certain multiplicative
prefactor. This prefactor has a dependence that is at least
polynomial in $d = 2^n$. 

\begin{equation}
% TODO fact check this!
\ell_d / \ell_1 = \Omega \left( \frac{d^2 - 1}{ \log |\mathcal{B}| } \right )
\end{equation}

efficient. This is an example of task modularity which allows us
to divide the effort of quantum compiling between the
single-qubit case and then decomposition to single-qubit gates and
$CNOT$. It is a heuristic which often results
in simple decompositions to implement in (classical) software.
It may not be asymptotically optimal compared to generic 
multi-qubit protocols. However, for small input sizes, it beats the




Now that we have handled the single-qubit case, how can we leverage this
to compile general $n$-qubit gates? We need a reduction to the basis
$\mathcal{Q} = U(2) \cup \{ CNOT \}$, as originally depicted in
Figure \ref{fig:qcompile}.
It turns out that almost any two-qubit gate plus arbitrary single-qubit
rotations are universal \cite{Bremner2002}. However, we will stick with CNOT
due to its other useful properties.
an $SU(2^n)$ matrix to 
The usual reduction uses
a two-level decomposition, as shown in several places.
We need to fact-check this.
\cite{Kitaev2002}

The optimal bound needed for this in terms of $CNOT$ gates in
the compiled output (the dominant cost) is still exponential
$O(4^n)$ \cite{Shende2004}.

\begin{table}[hbt!]
\begin{tabular}{|c|c|}
\hline
BBC+ \cite{Barenco1995a} & \\
Svore-Aho \cite{Aho2003} & $o(1.17\cdot 4^n - 3.51\cdot 4^n + 3.34)$ \\
Shende \cite{Shende2004a} & $o(0.48\cdot 4^n - 1.50\cdot 2^n + 1.34)$ \\
Shende \cite{Shende2004} & $\omega(0.25\cdot 4^n - 3n - 1)$ \\
\hline
\end{tabular}
\label{tab:multi}
\caption{}
\end{table}