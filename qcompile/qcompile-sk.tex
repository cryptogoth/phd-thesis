\section{The Solovay-Kitaev Algorithm}
\label{sec:qcompile-sk}

As one of the central results of quantum computation, it is worth
reviewing here the venerable Solovay-Kitaev (SK) algorithm for the
approximation of $SU(d)$ gates by a fixed, finite basis $\mathcal{B}$.
Although many recent results have surpassed SK in terms of efficiency,
they often do so by improving the base-level approximation of the
original SK algorithm. Moreover, many techniques for analyzing
and understanding quantum compilers were developed for SK, which
continues to be the best way to learn them. Finally, the overall
structure of the original SK algorithm is so simple, it is surprising
that it works so well. Therefore, it is worth
our time to review it here.

The essential structure of SK is to recursively generate nets of unitary
operators with
successively finer precision. At any given level of recursion, the input 
gate is divided up into two halves which can be
approximated with less precision. Our pseudo-code and explanation
follows the exposition in \cite{Dawson2005} and \cite{Harrow2001}

\begin{algorithmic}[1]
\STATE \textsc{function} $\tilde{U}_i \leftarrow$ SK$(U,n)$
\IF{$i = 0$}
\STATE $\tilde{U}_i \leftarrow $ BASIC-APPROX$(U)$
\ELSE
\STATE $\tilde{U}_{i-1} \leftarrow$ SK$(U, i-1)$
\STATE $A,B \leftarrow $ FACTOR$(U\tilde{U}^\dagger_{i-1})$
\STATE $\tilde{A}_{i-1} \leftarrow $ SK$(A, i-1)$
\STATE $\tilde{B}_{i-1} \leftarrow $ SK$(B, i-1)$
\STATE $\tilde{U}_i \leftarrow \tilde{A}_{i-1}\tilde{B}_{i-1}\tilde{A}^\dagger_{i-1}\tilde{B}^\dagger_{i-1}\tilde{U}_{i-1}$
\ENDIF
\STATE return $\tilde{U}_i$
\end{algorithmic}

Since the recursion must eventually bottom out, we must precompute some sequences
of gates from $\mathcal{B}$ up to length $l_0$. This is the classical
preprocessing step which requires upfront storage space for this
coarsest-grained net, where
each sequence is no more than $\epsilon_0$ from its nearest neighbor. According
to \cite{Dawson2005} the values of $l_0=16$ and $\epsilon_0 = 0.14$ using
operator norm distance is sufficient for most applications.
This step can be
done offline and reused across multiple runs of the compiler, assuming
$\mathcal{B}$ for your quantum computer doesn't change.

The BASIC-APPROX function above does a lookup (e.g. using some kd-tree search
maneuvers through higher-dimensional vector spaces) using this $\epsilon_0$-net,
and all higher recursive calls to SK are effectively constructing
finer $\epsilon$-nets on the fly as needed.

The FACTOR function performs a balanced group commutator decomposition,
$U = ABA^\dagger B^\dagger$, and then recursively approximates the $A$ and $B$
operators, again using SK. We denote by $\tilde{U}_i$ as the approximation
of $U$ using $i$ levels of SK recursion. When they are multiplied
together again, along with their inverses, their errors (which go like
$\epsilon$) are symmetric and cancel out in such a way that the resulting
product $U$ has errors which go like $\epsilon^2$, using the properties of
the balanced group commutator. In this manner, we can
eventually sharpen our desired error down to any value. A
geometric decomposition is used in the Dawson-Nielsen implementation \cite{Dawson2005},
while one based on a Baker-Campbell-Hausdorff approximation is used in the
Harrow implementation \cite{Harrow2001}. It is not
known which method converges more quickly to a desired gate in general.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% we still need to reconcile this 5^n with log^{3.97}(1/\epsilon)
% this is an evernote item, maybe it is already reconciled

Each level $i$ of recursion solves the problem of compiling 
$U_i$ by combining five gates compiled at the lower $i-1$ level.
Therefore, the compiled circuit size at the top-level is upper-bounded by $5^n$,
and
this is in general the same as the circuit depth (since not all gates in
$\mathcal{B}$ commute).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% we still need a discussion somewhere of the relationship between commuting
% operators and parallelizing them into the same timestep