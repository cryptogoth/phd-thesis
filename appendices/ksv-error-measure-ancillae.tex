
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Measurement Operators with Ancillae}
\label{sec:meas-ancillae}

However, this is not the most general case of a measurement operator.
We make \emph{three extensions} here which require cascading
two rounds of measurement through
an ancillary register. We now define a new
composite measurement operator $\tilde{Y}$
on this space with three subsystems corresponding to the input register
$\mathcal{N}$,
the intermediate ancillary register $\mathcal{B}^N$, and a final output register
$\mathcal{K}$ which approximates $Y$ from Equation \ref{eqn:y-ideal}.

\begin{equation}
\tilde{Y} : \mathcal{N} \otimes \mathcal{B}^N \otimes \mathcal{K}
\end{equation}

We will build up to an operational definition of $\tilde{Y}$ later, but first
we must motivate what it must achieve.

In the first round, we measure with our object in $\mathcal{N}$ and our
instrument in $\mathcal{B}^N$. Here we allow for garbage, which is our first
extension, described in \ref{subsec:garbage}.
In the second round, we measure with our object being the
instrument of the first round, in $\mathcal{B}^N$, and our instrument is
in $\mathcal{K}$. Here we allow for operations other than just copying from
$\mathcal{B}^N$ to $\mathcal{K}$, which is our second extension, described
in \ref{subsec:non-copy}. Finally, instead of implementing our ideal
$Y$ directly, we allow ourselves, and quantify what it means, to
approximate it as $\tilde{Y}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{First Extension: Measurement with Garbage}
\label{subsec:garbage}

To motivate why we need this new composite measurement $Y$ instead of just
using $W$ directly from the previous section, let's consider the problem of
garbage.
In general, only some of the information computed by $W$ into its
target register $\mathcal{K}$ above may be useful, but we generate some
garbage qubits (say, to make the operation reversible).
To be concrete, let's say that we have the following:

\begin{equation}
W: \mathcal{N} \otimes \mathcal{B}^N =
\sum_{j \in \Omega} \Pi_{\mathcal{L}_j} \otimes U_j \qquad
U_j : \mathcal{B}^N \rightarrow \mathcal{B}^N \qquad
U_j\ket{0} = \sum_{y,z} c_{y,z}(j)\ket{y,z}
\end{equation}

where $y \in \mathbb{B}^m$ represents the useful part of the result,
$z \in \mathbb{B}^{N-m}$ is garbage, and the complex weights
$c_{y,z} \in \mathbb{C}$
are functions of the index of the orthogonal decomposition of $\mathcal{N}$,
the number $j$. In many cases, we would like to uncompute this garbage in
order to use space efficiently.
We can do this using an uncomputing trick due to Charlie Bennett
\cite{Bennett1973} by first running an operation $U$ which may produce
garbage, copying out the useful part of the result to a
second register, and finally running $U^{\dagger}$ to uncompute the
input register.

Now we will give a more concrete definition for $Y$ in terms of
$W$ and the operation $V$ which simply copies a state $\ket{\psi} \in \mathcal{B}^N$
from the ancillary register to a state $\ket{\phi} in \mathcal{K}$ in the
output register using bitwise CNOTs, or bitwise addition modulo $2^n$ for an
$n$-qubit register. Then $Y = W^{-1}VW$, where $W$ is our operator from above
which computes a function with garbage, $V$ is our copy operation, and
$W^{-1}$ uncomputes the original function and it garbage. We make this
more rigorous in Equation \ref{eqn:wvw}.

\begin{eqnarray}
Y & = & WVW^{-1} : \mathcal{N} \otimes \mathcal{B}^N \otimes \mathcal{K} \\
W & = &
\sum_{j \in \Omega} \Pi_{\mathcal{L}_j} \otimes U_j \otimes I_{\mathcal{K}}\\
V & : & \ket{x} \otimes \ket{y} \otimes \ket{z} \rightarrow \ket{x} \otimes \ket{y} \otimes \ket{z \oplus y}
\label{eqn:wvw}
\end{eqnarray}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Second Extension: Measurement with a Non-Copy Operation}
\label{subsec:non-copy}

Our notion of measurement with garbage is still not the most general it could be.
For example, there is no reason why the decomposition of $\mathcal{K}$ has to
be the same as that for $\mathcal{B}^N$ or $\mathcal{N}$, or why we are limited
to strictly copying the useful output from $\mathcal{B}^N$ into $\mathcal{K}$.
We don't need to limit the function $f$ measured by $W$ to be invertible.
Furthermore, for practical reasons, there may be a more efficient way of encoding
the useful part of $f$'s output, or we may need to do further processing on it
as part of the algorithm we want to run.

To allow this, in this section, we allow an arbitrary orthogonal decomposition
$\mathcal{K} = \bigotimes_{y \in \Delta} \mathcal{M}_y$. This is the same as
allowing $V$ to be an arbitrary sum of projectors onto $\{\mathcal{M}_y\}$
and corresponding unitary operators $Q_y$ on $\mathcal{K}$.

\begin{equation}
V = \sum_{y \in \Delta} I_{\mathcal{N}} \otimes Q_y \otimes \Pi_{\mathcal{M}_y}
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Third Extension: Approximate Measurement}
\label{subsec:approx}

We can now allow a very general form of
measurement which allows garbage, non-copying uncomputation, and finally,
approximating a function. We will explain this last feature in this section.

We review that in the last two subsections we have been building up a
composite measurement operator $\tilde{Y} = W^{-1}VW$ which consists of 
these two operations on a space with three subsystems.

\begin{equation}
W = \sum_{j \in \Omega} \Pi_{\mathcal{L}_j} \otimes R_j \otimes I_{\mathcal{K}} \qquad
V = \sum_{y \in \Delta} I_{\mathcal{N}} \otimes \Pi_{\mathcal{M}_y} \otimes Q_y
\end{equation}

We now reveal that $\tilde{Y}$ approximates $Y$ from Equation \ref{eqn:y-ideal}.
What does this mean? For one operator, say $\tilde{X}$, to approximate another,
say $X$, within an error $\delta$ means that the maximum overlap between
any state $\ket{\eta}$ that is operated on by the difference
$\bar{X} = (\tilde{X} - X$) is at most
$\delta$. This is shown in Equation \ref{eqn:overlap}, and is analogous
to the method in Equation \ref{eqn:op-diff}.

\begin{equation}
\bra{\eta} \bar{X}^{\dagger} \bar{X} \ket{\eta} \le \delta
\label{eqn:overlap}
\end{equation}

Now how do we relate this to approximating a function
$f$ between the orthogonal decomposition indices of $\mathcal{N}$ and 
$\mathcal{K}$? And what does this latter concept mean?
It means that the conditional probabilities of
getting a given output index $y \in \Delta$ given an input index $j \in \Omega$,
namely $P(y \mid j) = \bra{0^N} R^{\dagger}_j \Pi_{\mathcal{M}_y} R_j \ket{0^N}$
satisfies Equation \ref{eqn:f-approx}. Approximating a function $f$ with
error probability $\epsilon$ means that the probability of getting the
correct answer $f(j)$ is bounded below by $1 - \epsilon$, and the probability
of getting any $y \ne f(j)$ is bounded above by $\epsilon$.

\begin{eqnarray}
P(f(j) \mid j) & \ge & 1 - \epsilon \\
\sum_{y \ne f(j)} P(y \mid j) & < & \epsilon
\label{eqn:f-approx}
\end{eqnarray}

In the next section, we will delve into detailed calculations of relating
$\delta$ and $\epsilon$ given the framework we have built up until now.
